{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Prediction\n",
    "\n",
    "Link prediction is the problem of predicting the existence of a link between two nodes in a network.\n",
    "\n",
    "<center><img src=\"images/link_prediction_problem.png\" width=\"300\"></center>\n",
    "\n",
    "It has many applications such as: \n",
    "- **friend recommendation in social networks:** The goal is to predict which pairs of users, who are not currently friends, are most likely to become friends based on the existing structure of the network and possibly other user-specific data.\n",
    "- **co-authorship prediction in citation networks:** Link prediction in co-authorship prediction within citation networks refers to the process of forecasting potential future collaborations between authors based on the existing structure and patterns of the network. In this context, a citation network is a graph where nodes represent authors (or papers), and edges represent co-authorship or citation relationships between them.\n",
    "- **movie recommendation in Netflix:** Link prediction in the context of movie recommendation on platforms like Netflix involves predicting the likelihood of a user forming a \"link\" (i.e., an interaction such as watching, rating, or liking) with a movie they have not yet interacted with. The goal is to recommend movies that the user is most likely to enjoy based on their past behavior and the behavior of other users with similar preferences.\n",
    "- **protein interaction prediction in biological networks:** Protein interaction prediction in biological networks, using link prediction, involves forecasting potential interactions between proteins within a biological network. This is crucial for understanding the molecular mechanisms underlying various biological processes and for identifying new targets for drug discovery.\n",
    "- **drug response prediction:** Link prediction in drug response prediction involves forecasting how different drugs will interact with various targets (such as proteins, genes, or cells) and how these interactions will result in a therapeutic response or adverse effect. The primary goal is to predict the effectiveness or toxicity of a drug on a specific biological target, which can help in personalized medicine, drug discovery, and understanding disease mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional Link Prediction Methods\n",
    "\n",
    "These methods can be categorized into three classes: \n",
    "- heuristic methods \n",
    "- latent-feature methods\n",
    "- content-based methods\n",
    "\n",
    "The link prediction problem has been studied extensively, leading to the development of numerous techniques. \n",
    "\n",
    "___\n",
    "\n",
    "We will first explore popular heuristics that utilize local and global neighborhood information. Can you think of a simple rule of thumb to predict whether two nodes should be connected?\n",
    "\n",
    "        \n",
    "- Common neighbors (CN): It is based on intuition that \"the more neighbors you have in common, the more likely you are to be connected\". This heuristic simply counts the number of neighbors two nodes ($x$ and $y$) have in common:\n",
    "\n",
    "\\begin{equation*}\n",
    "f_{CN}(x,y) = |\\mathcal{N}(x) \\cap \\mathcal{N}(y)|\n",
    "\\end{equation*}\n",
    "\n",
    "- Jaccard coefficient: measures the proportion of shared neighbors between two nodes. It builds on the idea of common neighbors but normalizes the count by the total number of neighbors. This method favors nodes with fewer neighbors over those with a high degree.\n",
    "\n",
    "\\begin{equation*}\n",
    "f_{Jaccard}(x,y) = \\frac{|\\mathcal{N}(x) \\cap \\mathcal{N}(y)|}{|\\mathcal{N}(x) \\cup \\mathcal{N}(y)|}\n",
    "\\end{equation*}\n",
    "\n",
    "- Preferential attachment (PA): measures link likelihood using the product of node degrees. PA assumes that node x is more likely to connect to node y if y has a high degree. For instance, in citation networks, a new paper is more likely to cite papers that already have many citations.\n",
    "\n",
    "- Adamic-Adar (AA): evaluates the strength of the link likelihood by considering the weight of common neighbors between two nodes. Specifically, each common neighbor $z$ contributes to the score, but its influence is reduced based on its degree, with the contribution being inversely proportional to the logarithm of its degree $ \\frac{1}{\\log|G(z)|} $. This approach down-weights high-degree common neighbors, under the assumption that common neighbors with many connections are less indicative of a potential link between the nodes in question.\n",
    "\n",
    "Note: The Adamic-Adar (AA) heuristic is considered a second-order heuristic because it evaluates the likelihood of a link between two nodes by considering not just the direct properties of the nodes themselves but also the properties of their shared neighbors (i.e., second-order neighbors).\n",
    "\n",
    "Three heuristics of CN, PA, and AA are illustrated in the following figure:\n",
    "<center><img src=\"images/link_prediction_heuristic.png\" width=\"600\"></center>\n",
    "<center><small>image from https://graph-neural-networks.github.io/static/file/chapter10.pdf</small></center>\n",
    "\n",
    "---\n",
    "\n",
    "\"One of the most popular latent feature methods is **matrix factorization**. This approach factorizes the observed adjacency matrix $A$ of the network into the product of a low-rank latent embedding matrix $Z \\in \\mathbb{R}^{n \\times k}$ and its transpose (where $n$ is the number of nodes and $k$ is the dimension of hidden embeddings). Essentially, it approximates the edge between nodes $i$ and $j$ using their $k$-dimensional latent embeddings, $z_i$ and $z_j$: $\\hat{A}_{i,j} = z^T_i z_j$.\n",
    "<center><img src=\"images/matrix factorization concept.png\" width=500></center>\n",
    "\n",
    "Intuitively, if nodes $i$ and $j$ are similar, the dot product $z_i^T z_j$ should be high, indicating a likely link between them. This dot product can be used to approximate each element (link) in the adjacency matrix.\n",
    "\n",
    "The method then minimizes the mean squared error between the reconstructed adjacency matrix and the true adjacency matrix over the observed edges to learn these latent embeddings: $L= \\sum_{(i,j) \\in E} (A_{i,j}-\\hat{A}_{i,j})^2$.\n",
    "\n",
    "---\n",
    "\n",
    "However, both heuristic methods and latent-feature methods rely solely on the network’s topology and do not incorporate node features when creating embeddings. Content-based methods use specific features associated with nodes to predict links, which is common in recommender systems. For example, in citation networks, the words used in papers can serve as features. In social networks, a user’s profile details, like their age or interests, are used as features. However, content-based methods often perform worse than heuristic and latent-feature methods because they don’t use the connections between nodes in the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
